"""
LangGraph Reactive Agent for FortuneDiary chat.

Uses `create_react_agent` (prebuilt ReAct loop) with:
- Google Gemini as LLM
- AsyncPostgresSaver for conversation memory
- Diary RAG search as first tool
"""
from __future__ import annotations

import logging
from typing import Optional

from langchain_core.tools import tool
from langchain_core.runnables import RunnableConfig
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver
from langgraph.prebuilt import create_react_agent
from psycopg_pool import AsyncConnectionPool

from app.config import SUPABASE_DB_URI, GOOGLE_API_KEY, DEFAULT_CHAT_MODEL
from app.agent.prompts import build_system_prompt
from app.services.vector_service import vector_service
from app.services.bazi_service import bazi_service
from app.services.tarot_service import tarot_service
from app.core.db import supabase

logger = logging.getLogger(__name__)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Tools (defined here so they can read RunnableConfig for user_id)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@tool
async def search_diaries(query: str, config: RunnableConfig, max_results: int = 5) -> str:
    """æœç´¢ç”¨æˆ·è¿‡å»çš„æ—¥è®°å†…å®¹ã€‚å½“ç”¨æˆ·æåˆ°è¿‡å»å†™çš„ä¸œè¥¿ã€æƒ³å›é¡¾æŸæ®µç»å†ã€æˆ–è€…é—®ã€Œæˆ‘ä¹‹å‰æœ‰æ²¡æœ‰å†™è¿‡å…³äº...ã€æ—¶ä½¿ç”¨è¿™ä¸ªå·¥å…·ã€‚"""
    user_id = config.get("configurable", {}).get("user_id", "")
    if not user_id:
        return "æ— æ³•æœç´¢æ—¥è®°ï¼šç¼ºå°‘ç”¨æˆ·ä¿¡æ¯ã€‚"

    try:
        results = await vector_service.search_similar_diaries(
            user_id=user_id,
            query=query,
            max_results=max_results,
        )
        if not results:
            return f"æ²¡æœ‰æ‰¾åˆ°ä¸ã€Œ{query}ã€ç›¸å…³çš„æ—¥è®°è®°å½•ã€‚"

        parts = []
        for i, r in enumerate(results, 1):
            preview = r.get("content_preview", "").strip()
            created = r.get("created_at", "æœªçŸ¥æ—¥æœŸ")
            sim = r.get("similarity", 0)
            parts.append(f"[{i}] æ—¥æœŸ: {created} (ç›¸å…³åº¦: {sim:.2f})\n{preview}")
        return "\n\n---\n\n".join(parts)

    except Exception as e:
        logger.error(f"Diary search tool error: {e}", exc_info=True)
        return "æ—¥è®°æœç´¢å‡ºé”™äº†ï¼Œè¯·ç¨åå†è¯•ã€‚"


def _get_user_birth_date(user_id: str):
    """ä» profiles è¡¨è·å–ç”¨æˆ·ç”Ÿæ—¥"""
    from datetime import datetime as dt
    resp = supabase.table("profiles").select("birth_datetime").eq("id", user_id).single().execute()
    if resp.data and resp.data.get("birth_datetime"):
        return dt.fromisoformat(resp.data["birth_datetime"]).date()
    return None


@tool
def query_bazi_info(config: RunnableConfig) -> str:
    """æŸ¥è¯¢ç”¨æˆ·çš„å…«å­—å‘½ç›˜ä¿¡æ¯ã€‚å½“ç”¨æˆ·é—®åˆ°è‡ªå·±çš„å…«å­—ã€æ—¥ä¸»ã€äº”è¡Œã€ä½“è´¨å¼ºå¼±ã€ä»Šæ—¥æµæ—¥è¿åŠ¿ç­‰å‘½ç†ç›¸å…³é—®é¢˜æ—¶ä½¿ç”¨ã€‚"""
    from datetime import date
    user_id = config.get("configurable", {}).get("user_id", "")
    if not user_id:
        return "æ— æ³•æŸ¥è¯¢å…«å­—ï¼šç¼ºå°‘ç”¨æˆ·ä¿¡æ¯ã€‚"
    try:
        birth_date = _get_user_birth_date(user_id)
        if not birth_date:
            return "ä½ è¿˜æ²¡æœ‰è®¾ç½®ç”Ÿæ—¥ï¼Œè¯·å…ˆåœ¨è®¾ç½®ä¸­å¡«å†™å‡ºç”Ÿæ—¥æœŸã€‚"
        bazi = bazi_service.calculate_bazi(birth_date)
        flow = bazi_service.analyze_daily_flow(birth_date, target_date=date.today())
        return (
            f"æ—¥ä¸»: {bazi['day_master']} | ä½“è´¨: {bazi['body_strength']}\n"
            f"å››æŸ±: {bazi['year_pillar']} {bazi['month_pillar']} {bazi['day_pillar']} {bazi['hour_pillar']}\n"
            f"ä»Šæ—¥æµæ—¥: {flow['daily_pillar']['stem']}{flow['daily_pillar']['branch']}\n"
            f"å¤©å¹²å½±å“: {flow['stem_influence']['relation']} â€” {flow['stem_influence']['analysis']}\n"
            f"åœ°æ”¯å½±å“: {flow['branch_influence']['relation']} â€” {flow['branch_influence']['analysis']}\n"
            f"åäºŒé•¿ç”Ÿ: {flow['energy_phase']} | è´µäººåˆ†: {flow['nobleman_score']}"
        )
    except Exception as e:
        logger.error(f"BaZi tool error: {e}", exc_info=True)
        return "å…«å­—æŸ¥è¯¢å‡ºé”™äº†ï¼Œè¯·ç¨åå†è¯•ã€‚"


@tool
def query_tarot_info(config: RunnableConfig) -> str:
    """æŸ¥è¯¢ç”¨æˆ·ä»Šæ—¥å¡”ç½—ç‰Œä¿¡æ¯ã€‚å½“ç”¨æˆ·é—®åˆ°ä»Šå¤©çš„å¡”ç½—ç‰Œã€ç‰Œé¢å«ä¹‰ã€æŠ½åˆ°äº†ä»€ä¹ˆç‰Œç­‰å¡”ç½—ç›¸å…³é—®é¢˜æ—¶ä½¿ç”¨ã€‚"""
    from datetime import date
    user_id = config.get("configurable", {}).get("user_id", "")
    if not user_id:
        return "æ— æ³•æŸ¥è¯¢å¡”ç½—ï¼šç¼ºå°‘ç”¨æˆ·ä¿¡æ¯ã€‚"
    try:
        today = date.today()
        reading = tarot_service.draw_daily_card(user_id, today)
        if "error" in reading:
            return f"å¡”ç½—æŸ¥è¯¢å¤±è´¥ï¼š{reading['error']}"
        card = reading.get("card", {})
        orientation = reading.get("orientation", "upright")
        ori_label = "æ­£ä½" if orientation == "upright" else "é€†ä½"
        meaning = card.get("meaning_up") if orientation == "upright" else card.get("meaning_down")
        return (
            f"ä»Šæ—¥å¡”ç½—: {card.get('card_name', 'æœªçŸ¥')} ({ori_label})\n"
            f"ç‰Œä¹‰: {meaning}\n"
            f"æè¿°: {card.get('description', '')}"
        )
    except Exception as e:
        logger.error(f"Tarot tool error: {e}", exc_info=True)
        return "å¡”ç½—æŸ¥è¯¢å‡ºé”™äº†ï¼Œè¯·ç¨åå†è¯•ã€‚"


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Agent service
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class ChatAgentService:
    """
    Manages the LangGraph reactive agent lifecycle.

    - One shared connection pool + checkpointer
    - One compiled graph (stateless â€” state lives in the checkpointer)
    - Per-request: pass thread_id + user_id through config
    """

    def __init__(self):
        self.pool: Optional[AsyncConnectionPool] = None
        self.graph = None
        self._initialized = False

    # â”€â”€ lifecycle â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def initialize(self):
        """Call once at app startup."""
        if self._initialized:
            return

        if not SUPABASE_DB_URI:
            logger.warning("âš ï¸  SUPABASE_DB_URI not set â€” agent disabled")
            return
        if not GOOGLE_API_KEY:
            logger.warning("âš ï¸  GOOGLE_API_KEY not set â€” agent disabled")
            return

        try:
            # 1. Postgres connection pool
            self.pool = AsyncConnectionPool(
                conninfo=SUPABASE_DB_URI,
                max_size=20,
                min_size=2,
                open=False,
                kwargs={"prepare_threshold": None},
            )
            await self.pool.open()
            logger.info("âœ… DB pool opened")

            # 2. Run checkpointer migrations once
            async with self.pool.connection() as conn:
                await conn.set_autocommit(True)
                checkpointer = AsyncPostgresSaver(conn)
                await checkpointer.setup()
            logger.info("âœ… Checkpointer tables ready")

            # 3. Build the graph (once â€” it's reusable)
            model = ChatGoogleGenerativeAI(
                model=DEFAULT_CHAT_MODEL,
                google_api_key=GOOGLE_API_KEY,
                temperature=0.7,
            )

            # We create the checkpointer from the pool for the compiled graph.
            # create_react_agent compiles a graph with the ReAct loop baked in.
            graph_checkpointer = AsyncPostgresSaver(self.pool)
            self.graph = create_react_agent(
                model=model,
                tools=[search_diaries, query_bazi_info, query_tarot_info],
                checkpointer=graph_checkpointer,
            )

            self._initialized = True
            logger.info(f"ğŸ‰ Chat agent ready  (model={DEFAULT_CHAT_MODEL})")

        except Exception as e:
            logger.error(f"âŒ Agent init failed: {e}", exc_info=True)
            if self.pool:
                try:
                    await self.pool.close()
                except Exception:
                    pass
                self.pool = None
            self._initialized = False

    async def shutdown(self):
        if self.pool:
            await self.pool.close()
            logger.info("Agent pool closed")

    # â”€â”€ public API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def chat(
        self,
        conversation_id: str,
        user_id: str,
        message: str,
        user_profile: str = "",
        today_fortune: dict | None = None,
    ) -> str:
        """
        Send a message and get a full response.

        The system prompt (with fortune + profile context) is prepended
        as the first message only when starting a new conversation.
        LangGraph's checkpointer handles history automatically.
        """
        if not self._initialized or not self.graph:
            raise RuntimeError("Agent not initialized")

        config = {
            "configurable": {
                "thread_id": conversation_id,
                "user_id": user_id,
            }
        }

        # Build input messages
        messages = []

        # Check if this is a fresh conversation (no checkpoint yet)
        state = await self.graph.aget_state(config)
        if not state or not state.values.get("messages"):
            # First turn â€” inject system prompt
            system_prompt = build_system_prompt(
                user_profile=user_profile,
                today_fortune=today_fortune,
            )
            messages.append({"role": "system", "content": system_prompt})

        messages.append({"role": "user", "content": message})

        result = await self.graph.ainvoke({"messages": messages}, config)

        # Extract the last AI message
        if result and "messages" in result and result["messages"]:
            last = result["messages"][-1]
            if hasattr(last, "content"):
                content = last.content
                if isinstance(content, list):
                    return "".join(
                        item.get("text", "") if isinstance(item, dict) else str(item)
                        for item in content
                    )
                return content
        return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›å¤ã€‚"

    async def chat_stream(
        self,
        conversation_id: str,
        user_id: str,
        message: str,
        user_profile: str = "",
        today_fortune: dict | None = None,
    ):
        """
        Streaming version â€” yields token chunks as they arrive.
        """
        if not self._initialized or not self.graph:
            raise RuntimeError("Agent not initialized")

        config = {
            "configurable": {
                "thread_id": conversation_id,
                "user_id": user_id,
            }
        }

        messages = []
        state = await self.graph.aget_state(config)
        if not state or not state.values.get("messages"):
            system_prompt = build_system_prompt(
                user_profile=user_profile,
                today_fortune=today_fortune,
            )
            messages.append({"role": "system", "content": system_prompt})

        messages.append({"role": "user", "content": message})

        async for chunk, metadata in self.graph.astream(
            {"messages": messages},
            config,
            stream_mode="messages",
        ):
            if hasattr(chunk, "content") and chunk.content:
                content = chunk.content
                if isinstance(content, list):
                    yield "".join(
                        item.get("text", "") if isinstance(item, dict) else str(item)
                        for item in content
                    )
                else:
                    yield content


# â”€â”€ Singleton â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

chat_agent = ChatAgentService()
