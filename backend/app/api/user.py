import os
import asyncio
from fastapi import APIRouter, Depends, HTTPException, status, Query, UploadFile, File
from typing import Dict, Any, List
from datetime import date, datetime, timedelta, timezone
import logging
import base64

from ..models.user import User
from ..models.fortune import UserProfileUpdate, UserPreferencesUpdate, ReminderSettingsUpdate, OnboardingData
from .auth import get_current_user
from ..core.db import supabase

router = APIRouter()
logging.basicConfig(level=logging.INFO)

@router.get("/profile")
async def get_user_profile(current_user: User = Depends(get_current_user)):
    """è·å–ç”¨æˆ·å®Œæ•´æ¡£æ¡ˆä¿¡æ¯ï¼ˆåŒ…å«æ‰€æœ‰æ•°æ®ï¼šåŸºæœ¬ä¿¡æ¯ã€ç»Ÿè®¡ã€åå¥½ã€æé†’è®¾ç½®ï¼‰"""
    try:
        user_id = str(current_user.id)
        user_email = current_user.email # ç›´æ¥ä»current_userè·å–email
        logging.info(f"\n{'='*80}")
        logging.info(f"[GET_PROFILE] ğŸ” å¼€å§‹è·å–ç”¨æˆ·æ¡£æ¡ˆ")
        logging.info(f"[GET_PROFILE] ğŸ‘¤ å½“å‰ç™»å½•ç”¨æˆ·: ID={user_id}, Email={user_email}")
        
        # è·å–ç”¨æˆ·æ¡£æ¡ˆä¿¡æ¯ï¼ˆä» profiles è¡¨ï¼‰
        try:
            profile_response = supabase.table("profiles").select("*").eq("id", user_id).single().execute()
            profile_data = profile_response.data if profile_response.data else {}
        except Exception as e:
            logging.warning(f"[GET_PROFILE] âš ï¸ ç”¨æˆ·æ¡£æ¡ˆä¸å­˜åœ¨ï¼Œè¿”å›ç©ºæ¡£æ¡ˆ: {e}")
            profile_data = {}
        logging.info(f"[GET_PROFILE] ğŸ“‹ æ¡£æ¡ˆæ•°æ®: {profile_data}")
        
        # è·å–ç”¨æˆ·åå¥½è®¾ç½®ï¼ˆä» fortune_categories å­—æ®µæˆ– user_preferences è¡¨ï¼‰
        user_focus_areas = profile_data.get("fortune_categories", ["overall", "career", "love", "wealth", "study", "health"])
        
        # è·å–æé†’è®¾ç½®å’Œéšç§è®¾ç½®
        reminder_settings = {}
        privacy_settings = {}
        try:
            preferences_response = supabase.table("user_preferences").select("*").eq("user_id", user_id).maybe_single().execute()
            if preferences_response and preferences_response.data:
                logging.info(f"[GET_PROFILE] âš™ï¸ åå¥½è®¾ç½®æ•°æ®: {preferences_response.data}")

                # æ³¨æ„ï¼šä¸å†ä½¿ç”¨ user_preferences.focus_areas å­—æ®µï¼ˆå·²åºŸå¼ƒï¼‰
                # å…³æ³¨é¢†åŸŸç»Ÿä¸€ä» profiles.fortune_categories è¯»å–ï¼ˆç¬¬37è¡Œï¼‰
                # è¯¥å­—æ®µé€šè¿‡ PUT /api/user/preferences æ¥å£æ›´æ–°åˆ° profiles.fortune_categories
                # æ—§ç‰ˆæœ¬çš„ focus_areas æ•°æ®å¯èƒ½å­˜åœ¨ä½†ä¸å†ä½¿ç”¨ï¼Œé¿å…æ•°æ®ä¸ä¸€è‡´

                if preferences_response.data.get("reminder_settings"):
                    reminder_settings = preferences_response.data.get("reminder_settings")
                if preferences_response.data.get("privacy_settings"):
                    privacy_settings = preferences_response.data.get("privacy_settings")
        except Exception as e:
            logging.warning(f"[GET_PROFILE] âš ï¸ è·å–ç”¨æˆ·åå¥½è®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
        
        # å¦‚æœæ²¡æœ‰æé†’è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not reminder_settings:
            reminder_settings = {
                "fortuneReminder": {"isEnabled": True, "time": "08:00:00", "days": [1,2,3,4,5,6,7]},
                "diaryReminder": {"isEnabled": True, "time": "21:00:00", "days": [1,2,3,4,5,6,7]},
                "summaryReminder": {"isEnabled": True, "time": "20:00:00", "days": [7]}
            }

        # å¦‚æœæ²¡æœ‰éšç§è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if not privacy_settings:
            privacy_settings = {
                "isProfilePublic": False,
                "allowDataAnalysis": True,
                "shareUsageStats": False
            }
        
        # è·å–ç”¨æˆ·ä½¿ç”¨ç»Ÿè®¡
        stats = await _calculate_user_stats(user_id)
        logging.info(f"[GET_PROFILE] ğŸ“Š ä½¿ç”¨ç»Ÿè®¡: {stats}")
        
        # è§£æå‡ºç”Ÿæ—¶é—´å’Œæ—¥æœŸ - æ•°æ®åº“æ ¼å¼: "1996-02-16 10:50:00"
        birth_datetime = profile_data.get("birth_datetime")
        if birth_datetime:
            # å°†ç©ºæ ¼æ›¿æ¢ä¸ºTï¼Œè½¬ä¸ºISOæ ¼å¼: "1996-02-16T10:50:00"
            birthTime = birth_datetime.replace(" ", "T")
            birthday = birth_datetime.split(" ")[0]  # æå–æ—¥æœŸéƒ¨åˆ†
            logging.info(f"[GET_PROFILE] ğŸ‚ ç”Ÿæ—¥æ•°æ®: åŸå§‹={birth_datetime}, birthTime={birthTime}, birthday={birthday}")
        else:
            birthTime = None
            birthday = None
        
        # æ„å»ºå®Œæ•´çš„ç”¨æˆ·æ¡£æ¡ˆï¼ˆç›´æ¥è¿”å›æ•°æ®åº“å­—æ®µåï¼Œä¸åšè½¬æ¢ï¼‰
        logging.info(f"[GET_PROFILE] ğŸ” full_name from DB: '{profile_data.get('full_name')}'")
        logging.info(f"[GET_PROFILE] ğŸ” avatar_url from DB: '{profile_data.get('avatar_url')}'")

        profile = {
            "id": user_id,
            "email": user_email,
            "username": profile_data.get("username"),
            "full_name": profile_data.get("full_name", ""),
            "avatar_url": profile_data.get("avatar_url"),
            "birth_datetime": profile_data.get("birth_datetime"),
            "birth_location": profile_data.get("birth_location"),
            "birth_timezone": profile_data.get("birth_timezone"),
            "timezone": profile_data.get("timezone", "Asia/Shanghai"),
            "gender": profile_data.get("gender"),
            "fortune_categories": profile_data.get("fortune_categories", ["overall", "career", "love", "wealth", "study", "health"]),
            "custom_voice_id": profile_data.get("custom_voice_id"),
            "is_time_unknown": profile_data.get("is_time_unknown", False),
            "created_at": profile_data.get("created_at"),
            "updated_at": profile_data.get("updated_at"),
            "onboarding_data": profile_data.get("onboarding_data"),
            "usageStats": stats,
            "preferences": {
                "focusAreas": user_focus_areas,
                "reminderSettings": reminder_settings,
                "privacySettings": privacy_settings
            }
        }
        
        logging.info(f"[GET_PROFILE] âœ… ç”¨æˆ·æ¡£æ¡ˆæ„å»ºå®Œæˆ")
        logging.info(f"[GET_PROFILE] ğŸ“¦ è¿”å›æ•°æ®: {profile}")
        logging.info(f"{'='*80}\n")
        return profile
        
    except Exception as e:
        logging.error(f"[GET_PROFILE] âŒ è·å–ç”¨æˆ·æ¡£æ¡ˆå¤±è´¥: user_id={user_id}, error={e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–ç”¨æˆ·æ¡£æ¡ˆå¤±è´¥: {str(e)}")

@router.put("/profile")
async def update_user_profile(
    profile_update: UserProfileUpdate, 
    current_user: User = Depends(get_current_user)
):
    """æ›´æ–°ç”¨æˆ·æ¡£æ¡ˆä¿¡æ¯ - æ›´æ–° profiles è¡¨"""
    try:
        user_id = str(current_user.id)
        logging.info(f"[UPDATE_PROFILE] æ›´æ–°ç”¨æˆ·æ¡£æ¡ˆ: user_id={user_id}")
        logging.debug(f"[UPDATE_PROFILE] æ¥æ”¶åˆ°çš„æ•°æ®: {profile_update.dict()}")
        
        # æ„å»ºæ›´æ–°æ•°æ®ï¼ˆæ˜ å°„åˆ° profiles è¡¨å­—æ®µï¼‰
        update_data = {}

        if profile_update.full_name is not None:
            update_data["full_name"] = profile_update.full_name
        
        if profile_update.gender is not None:
            # Frontend should send 'male', 'female', or 'other' (English only)
            update_data["gender"] = profile_update.gender
        
        # å¤„ç†ç”Ÿæ—¥å’Œå‡ºç”Ÿæ—¶é—´ - åˆå¹¶ä¸º birth_datetimeï¼ˆä¿ç•™ç”¨æˆ·è¾“å…¥çš„åŸå§‹æ—¶é—´ï¼Œä¸è¿›è¡Œæ—¶åŒºè½¬æ¢ï¼‰
        if profile_update.birthYear and profile_update.birthMonth and profile_update.birthDay:
            year = profile_update.birthYear
            month = profile_update.birthMonth.zfill(2)
            day = profile_update.birthDay.zfill(2)
            
            if profile_update.isTimeUnknown or not profile_update.birthHour:
                update_data["birth_datetime"] = f"{year}-{month}-{day}T12:00:00" # æ—¶è¾°ä¸è¯¦ï¼Œä½¿ç”¨åˆæ—¶
                update_data["is_time_unknown"] = True
            else:
                hour = profile_update.birthHour.zfill(2)
                minute = (profile_update.birthMinute or "0").zfill(2)
                update_data["birth_datetime"] = f"{year}-{month}-{day}T{hour}:{minute}:00"
                update_data["is_time_unknown"] = False
        
        # å¤„ç†å‡ºç”Ÿåœ°ç‚¹
        if profile_update.birthLocation:
            update_data["birth_location"] = profile_update.birthLocation
        
        # å­˜å‚¨å‡ºç”Ÿåœ°æ—¶åŒºåç§°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        if profile_update.birthTimezone:
            update_data["birth_timezone"] = profile_update.birthTimezone
        
        if profile_update.timezone is not None:
            update_data["timezone"] = profile_update.timezone
        
        # æ›´æ–° profiles è¡¨
        if update_data:
            update_data["updated_at"] = datetime.utcnow().isoformat()

            # é¦–å…ˆæ£€æŸ¥ profile æ˜¯å¦å­˜åœ¨å¹¶è·å–æ—§æ•°æ®
            check_response = supabase.table("profiles").select("*").eq("id", user_id).execute()

            old_profile_data = check_response.data[0] if check_response.data else {}

            if not check_response.data:
                # Profile ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°çš„
                update_data["id"] = user_id
                response = supabase.table("profiles").insert(update_data).execute()
            else:
                # Profile å­˜åœ¨ï¼Œæ›´æ–°
                response = supabase.table("profiles").update(update_data).eq("id", user_id).execute()

            if not response.data:
                raise HTTPException(status_code=500, detail="æ›´æ–°æ¡£æ¡ˆå¤±è´¥")

            # è®°å½•æ¡£æ¡ˆæ›´æ–°
            if old_profile_data:
                from ..services.daily_activity_service import daily_activity_service
                asyncio.create_task(
                    daily_activity_service.record_profile_update(user_id, old_profile_data, update_data)
                )

        logging.info(f"[UPDATE_PROFILE] ç”¨æˆ·æ¡£æ¡ˆæ›´æ–°æˆåŠŸ: user_id={user_id}, fields={list(update_data.keys())}")
        return {"message": "ç”¨æˆ·æ¡£æ¡ˆæ›´æ–°æˆåŠŸ", "updated_fields": list(update_data.keys())}

    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"[UPDATE_PROFILE] æ›´æ–°ç”¨æˆ·æ¡£æ¡ˆå¤±è´¥: user_id={current_user.id if current_user else 'unknown'}, error={e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ›´æ–°ç”¨æˆ·æ¡£æ¡ˆå¤±è´¥: {str(e)}")

@router.post("/avatar")
async def upload_avatar(
    file: UploadFile = File(...),
    current_user: User = Depends(get_current_user)
):
    """ä¸Šä¼ ç”¨æˆ·å¤´åƒåˆ° Supabase Storage"""
    try:
        user_id = str(current_user.id)
        logging.info(f"[UPLOAD_AVATAR] å¼€å§‹ä¸Šä¼ å¤´åƒ: user_id={user_id}, filename={file.filename}")

        # éªŒè¯æ–‡ä»¶ç±»å‹
        allowed_types = ["image/jpeg", "image/jpg", "image/png", "image/webp"]
        if file.content_type not in allowed_types:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file.content_type}ã€‚ä»…æ”¯æŒ JPEG, PNG, WebP"
            )

        # è¯»å–æ–‡ä»¶å†…å®¹
        file_content = await file.read()

        # éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆæœ€å¤§ 5MBï¼‰
        max_size = 5 * 1024 * 1024  # 5MB
        if len(file_content) > max_size:
            raise HTTPException(
                status_code=400,
                detail=f"æ–‡ä»¶è¿‡å¤§: {len(file_content)} bytesã€‚æœ€å¤§å…è®¸ 5MB"
            )

        # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨ç”¨æˆ·IDæ–‡ä»¶å¤¹ + æ—¶é—´æˆ³æ–‡ä»¶åï¼Œç¬¦åˆRLSç­–ç•¥ï¼‰
        file_extension = file.filename.split(".")[-1] if "." in file.filename else "jpg"
        timestamp = datetime.utcnow().strftime("%Y%m%d%H%M%S")
        storage_filename = f"{user_id}/avatar_{timestamp}.{file_extension}"  # æ ¼å¼: {user_id}/avatar_{timestamp}.jpg
        storage_path = f"avatars/{storage_filename}"

        logging.info(f"[UPLOAD_AVATAR] ä¸Šä¼ åˆ° Storage: {storage_path}")

        # ä¸Šä¼ åˆ° Supabase Storage
        try:
            # åˆ é™¤æ—§å¤´åƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            profile_response = supabase.table("profiles").select("avatar_url").eq("id", user_id).single().execute()
            if profile_response.data and profile_response.data.get("avatar_url"):
                old_avatar_url = profile_response.data["avatar_url"]
                # ä» URL ä¸­æå–æ–‡ä»¶è·¯å¾„ï¼ˆæ ¼å¼: {user_id}/avatar_{timestamp}.jpgï¼‰
                if "/object/public/avatars/" in old_avatar_url:
                    # æå– avatars/ åé¢çš„å®Œæ•´è·¯å¾„
                    old_path = old_avatar_url.split("/object/public/avatars/")[-1].split("?")[0]
                    try:
                        supabase.storage.from_("avatars").remove([old_path])
                        logging.info(f"[UPLOAD_AVATAR] å·²åˆ é™¤æ—§å¤´åƒ: {old_path}")
                    except Exception as e:
                        logging.warning(f"[UPLOAD_AVATAR] åˆ é™¤æ—§å¤´åƒå¤±è´¥ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰: {e}")

            # ä¸Šä¼ æ–°å¤´åƒ
            upload_response = supabase.storage.from_("avatars").upload(
                path=storage_filename,
                file=file_content,
                file_options={"content-type": file.content_type}
            )

            logging.info(f"[UPLOAD_AVATAR] Storage ä¸Šä¼ å“åº”: {upload_response}")

            # è·å–å…¬å¼€ URL
            public_url = supabase.storage.from_("avatars").get_public_url(storage_filename)
            logging.info(f"[UPLOAD_AVATAR] å…¬å¼€ URL: {public_url}")

        except Exception as storage_error:
            logging.error(f"[UPLOAD_AVATAR] Storage ä¸Šä¼ å¤±è´¥: {storage_error}", exc_info=True)
            raise HTTPException(
                status_code=500,
                detail=f"ä¸Šä¼ åˆ°å­˜å‚¨å¤±è´¥: {str(storage_error)}"
            )

        # æ›´æ–°æ•°æ®åº“ä¸­çš„å¤´åƒ URL
        try:
            update_data = {
                "avatar_url": public_url,
                "updated_at": datetime.utcnow().isoformat()
            }

            # æ£€æŸ¥ profile æ˜¯å¦å­˜åœ¨
            check_response = supabase.table("profiles").select("id").eq("id", user_id).execute()

            if not check_response.data:
                # Profile ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°çš„
                update_data["id"] = user_id
                db_response = supabase.table("profiles").insert(update_data).execute()
            else:
                # Profile å­˜åœ¨ï¼Œæ›´æ–°
                db_response = supabase.table("profiles").update(update_data).eq("id", user_id).execute()

            if not db_response.data:
                raise HTTPException(status_code=500, detail="æ›´æ–°æ•°æ®åº“å¤±è´¥")

            logging.info(f"[UPLOAD_AVATAR] æ•°æ®åº“æ›´æ–°æˆåŠŸ: avatar_url={public_url}")

        except HTTPException:
            raise
        except Exception as db_error:
            logging.error(f"[UPLOAD_AVATAR] æ•°æ®åº“æ›´æ–°å¤±è´¥: {db_error}", exc_info=True)
            raise HTTPException(
                status_code=500,
                detail=f"æ›´æ–°æ•°æ®åº“å¤±è´¥: {str(db_error)}"
            )

        logging.info(f"[UPLOAD_AVATAR] âœ… å¤´åƒä¸Šä¼ æˆåŠŸ: user_id={user_id}, url={public_url}")
        return {
            "message": "å¤´åƒä¸Šä¼ æˆåŠŸ",
            "avatar_url": public_url
        }

    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"[UPLOAD_AVATAR] ä¸Šä¼ å¤´åƒå¤±è´¥: user_id={current_user.id if current_user else 'unknown'}, error={e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ å¤´åƒå¤±è´¥: {str(e)}")


def build_initial_profile_text(
    full_name: str,
    gender: str,
    birth_year: str,
    birth_month: str,
    birth_day: str,
    onboarding_data: dict
) -> str:
    """å°† onboarding æ•°æ®è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€ï¼Œä½œä¸º Letta çš„åˆå§‹ç”»åƒ"""

    # å®šä¹‰æ˜ å°„å­—å…¸
    gender_map = {"male": "ç”·æ€§", "female": "å¥³æ€§", "other": "å…¶ä»–"}
    region_map = {"china": "ä¸­å›½", "usa": "ç¾å›½", "canada": "åŠ æ‹¿å¤§", "other": "å…¶ä»–åœ°åŒº"}
    work_type_map = {"fulltime": "å…¨èŒ", "parttime": "å…¼èŒ", "freelance": "è‡ªç”±èŒä¸š", "startup": "åˆ›ä¸šä¸­"}
    industry_map = {
        "tech": "ç§‘æŠ€äº’è”ç½‘", "finance": "é‡‘èå•†ä¸š", "health": "åŒ»ç–—å¥åº·",
        "creative": "åˆ›æ„åª’ä½“", "edu": "æ•™è‚²ç§‘ç ”", "other": "å…¶ä»–"
    }
    role_map = {
        "engineer": "å·¥ç¨‹æŠ€æœ¯", "product": "äº§å“ç­–åˆ’", "design": "è®¾è®¡åˆ›æ„",
        "marketing": "è¥é”€è¿è¥", "sales": "é”€å”®å•†åŠ¡", "admin": "ç®¡ç†è¡Œæ”¿", "other": "å…¶ä»–"
    }
    rhythm_map = {"remote": "å±…å®¶çº¿ä¸Š", "onsite": "ç°åœºçº¿ä¸‹", "hybrid": "æ··åˆæ¨¡å¼", "travel": "ç»å¸¸å‡ºå·®"}
    relationship_map = {"single": "å•èº«", "dating": "çº¦ä¼šä¸­", "partnered": "ç¨³å®šå…³ç³»", "complex": "ä¸€è¨€éš¾å°½"}
    income_map = {"salary": "å›ºå®šè–ªèµ„", "bonus": "å¥–é‡‘ææˆ", "invest": "æŠ•èµ„ç†è´¢", "side": "å‰¯ä¸šæ”¶å…¥", "other": "å…¶ä»–"}
    student_focus_map = {
        "study": "è¯¾ä¸šå­¦ä¹ ", "job": "æ‰¾å·¥ä½œå®ä¹ ", "skill": "æŠ€èƒ½æå‡",
        "network": "ç¤¾äº¤äººè„‰", "balance": "ç”Ÿæ´»å¹³è¡¡", "explore": "æ¢ç´¢æ–¹å‘"
    }

    lines = []

    # åŸºæœ¬ä¿¡æ¯
    if full_name:
        lines.append(f"æˆ‘å«{full_name}ï¼Œ")
    if gender:
        lines.append(f"æ€§åˆ«{gender_map.get(gender, gender)}ï¼Œ")
    if birth_year and birth_month and birth_day:
        lines.append(f"ç”Ÿæ—¥æ˜¯{birth_year}å¹´{birth_month}æœˆ{birth_day}æ—¥ã€‚")

    # åœ°åŒº
    if "region" in onboarding_data:
        region = onboarding_data["region"]
        lines.append(f"æˆ‘ç”Ÿæ´»åœ¨{region_map.get(region, region)}ã€‚")

    # çŠ¶æ€ï¼ˆå­¦ç”Ÿ/åœ¨èŒï¼‰
    if "status" in onboarding_data:
        status = onboarding_data["status"]
        if status == "student":
            lines.append("æˆ‘ç›®å‰æ˜¯å­¦ç”Ÿã€‚")

            # å­¦ç”Ÿè·¯å¾„ï¼šæœªæ¥æƒ³ä»äº‹çš„è¡Œä¸š
            if "student_industry" in onboarding_data:
                industries = onboarding_data["student_industry"]
                if isinstance(industries, list) and industries:
                    industry_names = [industry_map.get(ind, ind) for ind in industries]
                    lines.append(f"æœªæ¥æƒ³ä»äº‹ï¼š{', '.join(industry_names)}ã€‚")

            # å­¦ç”Ÿè·¯å¾„ï¼šå½“å‰å…³æ³¨
            if "student_focus" in onboarding_data:
                focus = onboarding_data["student_focus"]
                if isinstance(focus, list) and focus:
                    focus_names = [student_focus_map.get(f, f) for f in focus]
                    lines.append(f"ç°åœ¨æ›´å…³æ³¨ï¼š{', '.join(focus_names)}ã€‚")

            # å­¦ç”Ÿçš„æ„Ÿæƒ…çŠ¶æ€
            if "relationship_student" in onboarding_data:
                relationship = onboarding_data["relationship_student"]
                if isinstance(relationship, list) and relationship:
                    rel_names = [relationship_map.get(r, r) for r in relationship]
                    lines.append(f"æ„Ÿæƒ…çŠ¶æ€ï¼š{', '.join(rel_names)}ã€‚")

        elif status == "working":
            lines.append("æˆ‘ç›®å‰åœ¨èŒã€‚")

            # åœ¨èŒè·¯å¾„ï¼šå·¥ä½œç±»å‹
            if "work_type" in onboarding_data:
                work_types = onboarding_data["work_type"]
                if isinstance(work_types, list) and work_types:
                    type_names = [work_type_map.get(wt, wt) for wt in work_types]
                    lines.append(f"å·¥ä½œç±»å‹ï¼š{', '.join(type_names)}ã€‚")

            # åœ¨èŒè·¯å¾„ï¼šæ‰€åœ¨è¡Œä¸š
            if "industry" in onboarding_data:
                industries = onboarding_data["industry"]
                if isinstance(industries, list) and industries:
                    industry_names = [industry_map.get(ind, ind) for ind in industries]
                    lines.append(f"æ‰€åœ¨è¡Œä¸šï¼š{', '.join(industry_names)}ã€‚")

            # åœ¨èŒè·¯å¾„ï¼šä¸»è¦èŒè´£
            if "role" in onboarding_data:
                roles = onboarding_data["role"]
                if isinstance(roles, list) and roles:
                    role_names = [role_map.get(r, r) for r in roles]
                    lines.append(f"ä¸»è¦èŒè´£ï¼š{', '.join(role_names)}ã€‚")

            # åœ¨èŒè·¯å¾„ï¼šæ—¥å¸¸èŠ‚å¥
            if "rhythm" in onboarding_data:
                rhythms = onboarding_data["rhythm"]
                if isinstance(rhythms, list) and rhythms:
                    rhythm_names = [rhythm_map.get(rh, rh) for rh in rhythms]
                    lines.append(f"æ—¥å¸¸èŠ‚å¥ï¼š{', '.join(rhythm_names)}ã€‚")

            # åœ¨èŒçš„æ„Ÿæƒ…çŠ¶æ€
            if "relationship_working" in onboarding_data:
                relationship = onboarding_data["relationship_working"]
                if isinstance(relationship, list) and relationship:
                    rel_names = [relationship_map.get(r, r) for r in relationship]
                    lines.append(f"æ„Ÿæƒ…çŠ¶æ€ï¼š{', '.join(rel_names)}ã€‚")

            # åœ¨èŒè·¯å¾„ï¼šæ”¶å…¥æ¥æº
            if "income" in onboarding_data:
                incomes = onboarding_data["income"]
                if isinstance(incomes, list) and incomes:
                    income_names = [income_map.get(inc, inc) for inc in incomes]
                    lines.append(f"æ”¶å…¥æ¥æºï¼š{', '.join(income_names)}ã€‚")

    result = "".join(lines)
    return result if result else "ç”¨æˆ·å®Œæˆäº†åŸºæœ¬ä¿¡æ¯å¡«å†™ã€‚"

@router.post("/onboarding")
async def complete_onboarding(
    onboarding_data: OnboardingData,
    current_user: User = Depends(get_current_user)
):
    """å®Œæˆç”¨æˆ·Onboarding - ä¸€æ¬¡æ€§ä¿å­˜æ‰€æœ‰ç”¨æˆ·ä¿¡æ¯ï¼ˆæœ€ä½³å®è·µï¼‰"""
    try:
        user_id = str(current_user.id)
        logging.info(f"[ONBOARDING] å¼€å§‹å¤„ç†ç”¨æˆ·Onboarding: user_id={user_id}")
        logging.debug(f"[ONBOARDING] æ¥æ”¶åˆ°çš„æ•°æ®: {onboarding_data.dict()}")
        
        updated_sections = []
        
        # 1. æ›´æ–°ä¸ªäººä¿¡æ¯åˆ° profiles è¡¨
        profile_data = {}
        if onboarding_data.full_name:
            profile_data["full_name"] = onboarding_data.full_name
        if onboarding_data.gender:
            profile_data["gender"] = onboarding_data.gender
        
        # å¤„ç†ç”Ÿæ—¥å’Œå‡ºç”Ÿæ—¶é—´
        if onboarding_data.birthYear and onboarding_data.birthMonth and onboarding_data.birthDay:
            year = onboarding_data.birthYear
            month = onboarding_data.birthMonth.zfill(2)
            day = onboarding_data.birthDay.zfill(2)
            
            if onboarding_data.isTimeUnknown or not onboarding_data.birthHour:
                profile_data["birth_datetime"] = f"{year}-{month}-{day}T12:00:00" # æ—¶è¾°ä¸è¯¦ï¼Œä½¿ç”¨åˆæ—¶
                profile_data["is_time_unknown"] = True
            else:
                hour = onboarding_data.birthHour.zfill(2)
                minute = (onboarding_data.birthMinute or "0").zfill(2)
                profile_data["birth_datetime"] = f"{year}-{month}-{day}T{hour}:{minute}:00"
                profile_data["is_time_unknown"] = False
        
        # å¤„ç†å‡ºç”Ÿåœ°ç‚¹
        if onboarding_data.birthLocation:
            profile_data["birth_location"] = onboarding_data.birthLocation
        
        # å­˜å‚¨å‡ºç”Ÿåœ°æ—¶åŒºåç§°
        if onboarding_data.birthTimezone:
            profile_data["birth_timezone"] = onboarding_data.birthTimezone
        
        if onboarding_data.timezone:
            profile_data["timezone"] = onboarding_data.timezone

        # 2. æ›´æ–°å…³æ³¨é¢†åŸŸåˆ° profiles è¡¨
        if onboarding_data.focusAreas:
            valid_categories = ["overall", "career", "love", "wealth", "study", "health"]
            mapped_categories = [cat for cat in onboarding_data.focusAreas if cat in valid_categories]
            if mapped_categories:
                profile_data["fortune_categories"] = mapped_categories

        # 3. å­˜å‚¨é¢å¤–çš„é—®å·æ•°æ®åˆ° onboarding_data JSONB å­—æ®µ
        if onboarding_data.onboarding_data:
            profile_data["onboarding_data"] = onboarding_data.onboarding_data
            logging.info(f"[ONBOARDING] å­˜å‚¨é¢å¤–é—®å·æ•°æ®: {list(onboarding_data.onboarding_data.keys())}")

        # æ›´æ–° profiles è¡¨
        if profile_data:
            profile_data["updated_at"] = datetime.utcnow().isoformat()
            check_response = supabase.table("profiles").select("*").eq("id", user_id).execute()

            old_profile_data = check_response.data[0] if check_response.data else {}

            if not check_response.data:
                profile_data["id"] = user_id
                supabase.table("profiles").insert(profile_data).execute()
            else:
                supabase.table("profiles").update(profile_data).eq("id", user_id).execute()

            # è®°å½•æ¡£æ¡ˆæ›´æ–°
            if old_profile_data:
                from ..services.daily_activity_service import daily_activity_service
                asyncio.create_task(
                    daily_activity_service.record_profile_update(user_id, old_profile_data, profile_data)
                )

            updated_sections.append("profile")
            logging.info(f"[ONBOARDING] ä¸ªäººä¿¡æ¯æ›´æ–°æˆåŠŸ: user_id={user_id}")

        # 4. æ›´æ–°æé†’è®¾ç½®åˆ° user_preferences è¡¨
        if onboarding_data.reminderSettings:
            reminder_data = {}
            
            if onboarding_data.reminderSettings.fortuneReminder:
                reminder_data["fortuneReminder"] = onboarding_data.reminderSettings.fortuneReminder.dict()
            if onboarding_data.reminderSettings.diaryReminder:
                reminder_data["diaryReminder"] = onboarding_data.reminderSettings.diaryReminder.dict()
            if onboarding_data.reminderSettings.summaryReminder:
                reminder_data["summaryReminder"] = onboarding_data.reminderSettings.summaryReminder.dict()
            
            if reminder_data:
                pref_check = supabase.table("user_preferences").select("id").eq("user_id", user_id).execute()
                
                if not pref_check.data:
                    supabase.table("user_preferences").insert({
                        "user_id": user_id,
                        "reminder_settings": reminder_data
                    }).execute()
                else:
                    supabase.table("user_preferences").update({
                        "reminder_settings": reminder_data,
                        "updated_at": datetime.utcnow().isoformat()
                    }).eq("user_id", user_id).execute()
                
                updated_sections.append("reminders")
                logging.info(f"[ONBOARDING] æé†’è®¾ç½®æ›´æ–°æˆåŠŸ: user_id={user_id}")

        # 5. åˆå§‹åŒ– Letta ç”¨æˆ·ç”»åƒï¼ˆå¼‚æ­¥åå°ä»»åŠ¡ï¼‰
        if onboarding_data.onboarding_data:
            try:
                from ..services.letta_service import letta_service
                import asyncio

                # æ„å»ºåˆå§‹ç”»åƒæ–‡æœ¬
                initial_profile = build_initial_profile_text(
                    full_name=onboarding_data.full_name or "",
                    gender=onboarding_data.gender or "",
                    birth_year=onboarding_data.birthYear or "",
                    birth_month=onboarding_data.birthMonth or "",
                    birth_day=onboarding_data.birthDay or "",
                    onboarding_data=onboarding_data.onboarding_data
                )

                logging.info(f"[ONBOARDING] å‡†å¤‡åˆå§‹åŒ– Letta ç”»åƒ: user_id={user_id}")
                logging.debug(f"[ONBOARDING] åˆå§‹ç”»åƒæ–‡æœ¬: {initial_profile}")

                # åå°ä»»åŠ¡å–‚å…¥ Lettaï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
                async def ingest_to_letta():
                    try:
                        await letta_service.ingest_diary(
                            user_id=user_id,
                            diary_text=initial_profile,
                            diary_date=None
                        )
                        logging.info(f"âœ… [ONBOARDING] Letta åˆå§‹ç”»åƒå·²åˆ›å»º: user_id={user_id}")
                    except Exception as e:
                        logging.warning(f"âš ï¸ [ONBOARDING] Letta åˆå§‹åŒ–å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")

                asyncio.create_task(ingest_to_letta())
                updated_sections.append("letta_profile")

            except Exception as letta_error:
                logging.warning(f"âš ï¸ [ONBOARDING] Letta åˆå§‹åŒ–å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {letta_error}")

        logging.info(f"[ONBOARDING] Onboardingå®Œæˆ: user_id={user_id}, updated_sections={updated_sections}")
        return {
            "message": "Onboardingå®Œæˆ",
            "updated_sections": updated_sections,
            "success": True
        }
        
    except Exception as e:
        logging.error(f"[ONBOARDING] Onboardingå¤„ç†å¤±è´¥: user_id={current_user.id if current_user else 'unknown'}, error={e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Onboardingå¤„ç†å¤±è´¥: {str(e)}")

@router.get("/stats")
async def get_user_stats(current_user: User = Depends(get_current_user)):
    """è·å–ç”¨æˆ·ä½¿ç”¨ç»Ÿè®¡"""
    try:
        user_id = str(current_user.id)
        stats = await _calculate_user_stats(user_id)
        return stats
        
    except Exception as e:
        logging.error(f"è·å–ç”¨æˆ·ç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ç”¨æˆ·ç»Ÿè®¡å¤±è´¥: {str(e)}")

@router.put("/preferences")
async def update_user_preferences(
    preferences: UserPreferencesUpdate, 
    current_user: User = Depends(get_current_user)
):
    """æ›´æ–°ç”¨æˆ·åå¥½è®¾ç½® - æ›´æ–° profiles è¡¨çš„ fortune_categories"""
    try:
        user_id = str(current_user.id)
        logging.info(f"[UPDATE_PREFERENCES] æ›´æ–°ç”¨æˆ·åå¥½: user_id={user_id}")
        logging.debug(f"[UPDATE_PREFERENCES] æ¥æ”¶åˆ°çš„æ•°æ®: {preferences.dict()}")
        
        # å¦‚æœæœ‰ focusAreasï¼Œæ›´æ–° profiles è¡¨çš„ fortune_categories
        if preferences.focusAreas:
            # å‰ç«¯åº”è¯¥ç›´æ¥å‘é€è‹±æ–‡: ["career", "wealth", "love", "health", "study"]
            # è¿‡æ»¤æœ‰æ•ˆçš„ç±»åˆ«
            valid_categories = ["overall", "career", "love", "wealth", "study", "health"]
            mapped_categories = [cat for cat in preferences.focusAreas if cat in valid_categories]
            
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆç±»åˆ«ï¼Œä½¿ç”¨é»˜è®¤å€¼
            if not mapped_categories:
                mapped_categories = ["overall", "career", "love", "wealth", "study", "health"]
            
            # æ›´æ–° profiles è¡¨
            update_data = {
                "fortune_categories": mapped_categories,
                "updated_at": datetime.utcnow().isoformat()
            }
            
            # æ£€æŸ¥ profile æ˜¯å¦å­˜åœ¨ï¼ˆé€šå¸¸ç”±è§¦å‘å™¨åˆ›å»ºï¼‰
            check_response = supabase.table("profiles").select("id").eq("id", user_id).execute()
            
            if not check_response.data:
                # Profile ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°çš„ï¼ˆfallbackï¼Œæ­£å¸¸ä¸åº”è¯¥åˆ°è¿™é‡Œï¼‰
                update_data["id"] = user_id
                response = supabase.table("profiles").insert(update_data).execute()
            else:
                # Profile å­˜åœ¨ï¼Œæ›´æ–°
                response = supabase.table("profiles").update(update_data).eq("id", user_id).execute()
        
        # å¦‚æœæœ‰ reminderSettings æˆ– privacySettingsï¼Œå­˜å‚¨åˆ° user_preferences è¡¨
        if preferences.reminderSettings or preferences.privacySettings:
            preferences_data = {
                "user_id": user_id,
                "reminder_settings": preferences.reminderSettings.dict() if preferences.reminderSettings else {},
                "privacy_settings": preferences.privacySettings.dict() if preferences.privacySettings else {},
                "updated_at": datetime.utcnow().isoformat()
            }
            
            # ä½¿ç”¨upsertæ“ä½œï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºï¼Œå­˜åœ¨åˆ™æ›´æ–°
            # æŒ‡å®š on_conflict å‚æ•°æ¥å¤„ç† user_id å”¯ä¸€çº¦æŸå†²çª
            supabase.table("user_preferences").upsert(
                preferences_data,
                on_conflict="user_id"
            ).execute()
        
        logging.info(f"[UPDATE_PREFERENCES] ç”¨æˆ·åå¥½æ›´æ–°æˆåŠŸ: user_id={user_id}")
        return {"message": "ç”¨æˆ·åå¥½è®¾ç½®æ›´æ–°æˆåŠŸ"}
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"[UPDATE_PREFERENCES] æ›´æ–°ç”¨æˆ·åå¥½å¤±è´¥: user_id={current_user.id if current_user else 'unknown'}, error={e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ›´æ–°ç”¨æˆ·åå¥½è®¾ç½®å¤±è´¥: {str(e)}")

@router.get("/reminders")
async def get_reminder_settings(current_user: User = Depends(get_current_user)):
    """è·å–ç”¨æˆ·æé†’è®¾ç½®"""
    try:
        user_id = str(current_user.id)
        
        response = supabase.table("user_preferences").select("reminder_settings").eq("user_id", user_id).single().execute()
        
        if response.data and response.data.get("reminder_settings"):
            return response.data["reminder_settings"]
        else:
            # è¿”å›é»˜è®¤æé†’è®¾ç½®
            return {
                "fortuneReminder": {"isEnabled": True, "time": "08:00:00", "days": [1,2,3,4,5,6,7]},
                "diaryReminder": {"isEnabled": True, "time": "21:00:00", "days": [1,2,3,4,5,6,7]},
                "summaryReminder": {"isEnabled": True, "time": "20:00:00", "days": [7]} # å‘¨æ—¥
            }
            
    except Exception as e:
        logging.error(f"è·å–æé†’è®¾ç½®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æé†’è®¾ç½®å¤±è´¥: {str(e)}")

@router.put("/reminders")
async def update_reminder_settings(
    settings: ReminderSettingsUpdate, 
    current_user: User = Depends(get_current_user)
):
    """æ›´æ–°ç”¨æˆ·æé†’è®¾ç½®"""
    try:
        user_id = str(current_user.id)
        logging.info(f"[UPDATE_REMINDERS] æ›´æ–°æé†’è®¾ç½®: user_id={user_id}")
        
        # è·å–ç°æœ‰åå¥½è®¾ç½®
        response = supabase.table("user_preferences").select("*").eq("user_id", user_id).single().execute()
        
        if response.data:
            # æ›´æ–°ç°æœ‰è®¾ç½®
            current_settings = response.data.get("reminder_settings", {})
            current_settings.update(settings.dict())
            
            update_data = {
                "reminder_settings": current_settings,
                "updated_at": datetime.utcnow().isoformat()
            }
            
            supabase.table("user_preferences").update(update_data).eq("user_id", user_id).execute()
        else:
            # åˆ›å»ºæ–°çš„åå¥½è®¾ç½®
            preferences_data = {
                "user_id": user_id,
                "reminder_settings": settings.dict(),
                "focus_areas": [],
                "privacy_settings": {},
                "created_at": datetime.utcnow().isoformat(),
                "updated_at": datetime.utcnow().isoformat()
            }
            
            supabase.table("user_preferences").insert(preferences_data).execute()
        
        logging.info(f"[UPDATE_REMINDERS] æé†’è®¾ç½®æ›´æ–°æˆåŠŸ: user_id={user_id}")
        return {"message": "æé†’è®¾ç½®æ›´æ–°æˆåŠŸ"}
        
    except Exception as e:
        logging.error(f"[UPDATE_REMINDERS] æ›´æ–°æé†’è®¾ç½®å¤±è´¥: user_id={user_id}, error={e}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°æé†’è®¾ç½®å¤±è´¥: {str(e)}")

@router.post("/checkin")
async def user_checkin(current_user: User = Depends(get_current_user)):
    """ç”¨æˆ·æ¯æ—¥ç­¾åˆ°"""
    try:
        user_id = str(current_user.id)
        today = date.today().isoformat()
        
        # æ£€æŸ¥ä»Šæ—¥æ˜¯å¦å·²ç­¾åˆ°
        checkin_response = supabase.table("user_checkins").select("*").eq("user_id", user_id).eq("checkin_date", today).single().execute()
        
        if checkin_response.data:
            raise HTTPException(status_code=400, detail="ä»Šæ—¥å·²ç­¾åˆ°")
        
        # è®°å½•ç­¾åˆ°
        checkin_data = {
            "user_id": user_id,
            "checkin_date": today,
            "checkin_time": datetime.utcnow().isoformat()
        }
        
        supabase.table("user_checkins").insert(checkin_data).execute()
        
        # æ›´æ–°è¿ç»­ç­¾åˆ°å¤©æ•°
        await _update_consecutive_checkins(user_id)
        
        return {"message": "ç­¾åˆ°æˆåŠŸ", "checkin_date": today}
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"ç”¨æˆ·ç­¾åˆ°å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç­¾åˆ°å¤±è´¥: {str(e)}")

async def _calculate_user_stats(user_id: str) -> Dict[str, Any]:
    """è®¡ç®—ç”¨æˆ·ä½¿ç”¨ç»Ÿè®¡"""
    try:
        logging.info(f"[STATS] ğŸ“Š å¼€å§‹è®¡ç®—ç”¨æˆ·ç»Ÿè®¡: user_id={user_id}")
        now_utc = datetime.now(timezone.utc) # ä½¿ç”¨ aware datetime
        
        # è·å–ç”¨æˆ·æ³¨å†Œæ—¶é—´ï¼ˆä»profilesè¡¨ï¼‰
        registration_date = None
        try:
            profile_response = supabase.table("profiles").select("created_at").eq("id", user_id).single().execute()
            registration_date = profile_response.data.get("created_at") if profile_response.data else None
        except Exception as e:
            logging.warning(f"[STATS] âš ï¸ æ— æ³•è·å–æ³¨å†Œæ—¥æœŸ: {e}")
        logging.info(f"[STATS] ğŸ“… æ³¨å†Œæ—¥æœŸ: {registration_date}")
        
        # è®¡ç®—æ€»å¤©æ•°
        total_days = 0
        if registration_date:
            reg_date = datetime.fromisoformat(registration_date.replace('Z', '+00:00'))
            total_days = (now_utc - reg_date).days + 1
        logging.info(f"[STATS] ğŸ”¢ æ€»ä½¿ç”¨å¤©æ•°: {total_days}")
        
        # è·å–è¿ç»­ç­¾åˆ°å¤©æ•°
        consecutive_checkins = await _get_consecutive_checkins(user_id)
        logging.info(f"[STATS] âœ… è¿ç»­ç­¾åˆ°å¤©æ•°: {consecutive_checkins}")
        
        # è·å–æ—¥è®°ç»Ÿè®¡
        diary_response = supabase.table("diary_entries").select("created_at").eq("user_id", user_id).execute()
        total_diaries = len(diary_response.data) if diary_response.data else 0
        logging.info(f"[STATS] ğŸ“– æ€»æ—¥è®°æ•°: {total_diaries}")
        
        # è®¡ç®—æœ¬æœˆæ—¥è®°æ•°
        current_month = now_utc.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
        monthly_diaries = 0
        if diary_response.data:
            for diary in diary_response.data:
                diary_date = datetime.fromisoformat(diary["created_at"].replace('Z', '+00:00'))
                if diary_date >= current_month:
                    monthly_diaries += 1
        logging.info(f"[STATS] ğŸ“Š æœ¬æœˆæ—¥è®°æ•°: {monthly_diaries}")
        
        # è·å–å¯¹è¯ç»Ÿè®¡
        chat_response = supabase.table("chat_messages").select("id").eq("user_id", user_id).execute()
        total_conversations = len(chat_response.data) if chat_response.data else 0
        logging.info(f"[STATS] ğŸ’¬ æ€»å¯¹è¯æ•°: {total_conversations}")
        
        # è·å–æ€»å­—æ•°
        total_words = 0
        if diary_response.data:
            for diary in diary_response.data:
                content = diary.get("content", "")
                total_words += len(content)
        logging.info(f"[STATS] ğŸ“ æ€»å­—æ•°: {total_words}")
        
        # è·å–æœ€åæ´»è·ƒæ—¶é—´
        last_active = None
        if diary_response.data:
            latest_diary = max(diary_response.data, key=lambda x: x["created_at"])
            last_active = latest_diary["created_at"]
        logging.info(f"[STATS] â° æœ€åæ´»è·ƒ: {last_active}")
        
        stats_result = {
            "registrationDate": registration_date,
            "totalDays": total_days,
            "consecutiveCheckins": consecutive_checkins,
            "totalDiaries": total_diaries,
            "monthlyDiaries": monthly_diaries,
            "totalConversations": total_conversations,
            "totalWords": total_words,
            "lastActiveDate": last_active
        }
        logging.info(f"[STATS] âœ… ç»Ÿè®¡è®¡ç®—å®Œæˆ: {stats_result}")
        return stats_result
        
    except Exception as e:
        logging.error(f"è®¡ç®—ç”¨æˆ·ç»Ÿè®¡å¤±è´¥: {e}")
        return {
            "registrationDate": None,
            "totalDays": 0,
            "consecutiveCheckins": 0,
            "totalDiaries": 0,
            "monthlyDiaries": 0,
            "totalConversations": 0,
            "totalWords": 0,
            "lastActiveDate": None
        }

async def _get_consecutive_checkins(user_id: str) -> int:
    """è·å–ç”¨æˆ·è¿ç»­ç­¾åˆ°å¤©æ•°"""
    try:
        now_utc = datetime.now(timezone.utc) # ä½¿ç”¨ aware datetime
        
        # è·å–æœ€è¿‘30å¤©çš„ç­¾åˆ°è®°å½•
        thirty_days_ago = (now_utc - timedelta(days=30)).date().isoformat()
        
        response = supabase.table("user_checkins").select("checkin_date").eq("user_id", user_id).gte("checkin_date", thirty_days_ago).order("checkin_date", desc=True).execute()
        
        if not response.data:
            return 0
        
        checkin_dates = [datetime.fromisoformat(date_str).date() for date_str in response.data]
        checkin_dates.sort(reverse=True)
        
        # è®¡ç®—è¿ç»­ç­¾åˆ°å¤©æ•°
        consecutive = 0
        current_date = now_utc.date()
        
        for i, checkin_date in enumerate(checkin_dates):
            if i == 0:
                if checkin_date == current_date:
                    consecutive = 1
                else:
                    break
            else:
                expected_date = checkin_dates[i-1] - timedelta(days=1)
                if checkin_date == expected_date:
                    consecutive += 1
                else:
                    break
        
        return consecutive
        
    except Exception as e:
        logging.error(f"è·å–è¿ç»­ç­¾åˆ°å¤©æ•°å¤±è´¥: {e}")
        return 0

async def _update_consecutive_checkins(user_id: str):
    """æ›´æ–°ç”¨æˆ·è¿ç»­ç­¾åˆ°å¤©æ•°"""
    try:
        consecutive_days = await _get_consecutive_checkins(user_id)
        
        # æ›´æ–°ç”¨æˆ·åå¥½è¡¨ä¸­çš„ç»Ÿè®¡ä¿¡æ¯
        update_data = {
            "consecutive_checkins": consecutive_days,
            "updated_at": datetime.utcnow().isoformat()
        }
        
        supabase.table("user_preferences").update(update_data).eq("user_id", user_id).execute()
        
    except Exception as e:
        logging.error(f"æ›´æ–°è¿ç»­ç­¾åˆ°å¤©æ•°å¤±è´¥: {e}") 

@router.get("/export")
async def export_user_data(
    format: str = Query("json", description="å¯¼å‡ºæ ¼å¼: json æˆ– csv"),
    include_fortunes: bool = Query(True, description="æ˜¯å¦åŒ…å«è¿åŠ¿æ•°æ®"),
    include_diaries: bool = Query(True, description="æ˜¯å¦åŒ…å«æ—¥è®°æ•°æ®"),
    include_chats: bool = Query(True, description="æ˜¯å¦åŒ…å«å¯¹è¯æ•°æ®"),
    current_user: User = Depends(get_current_user)
):
    """
    å¯¼å‡ºç”¨æˆ·æ•°æ®
    
    æ”¯æŒæ ¼å¼ï¼š
    - JSON: å®Œæ•´çš„æ•°æ®ç»“æ„ï¼Œé€‚åˆæ•°æ®è¿ç§»
    - CSV: è¡¨æ ¼æ ¼å¼ï¼Œé€‚åˆæ•°æ®åˆ†æ
    
    æ•°æ®èŒƒå›´ï¼š
    - è¿åŠ¿å†å²è®°å½•
    - æ—¥è®°å†…å®¹
    - AIå¯¹è¯è®°å½•
    - ç”¨æˆ·åå¥½è®¾ç½®
    """
    try:
        user_id = str(current_user.id)
        user_email = current_user.email
        
        # è·å–ç”¨æˆ·åŸºç¡€ä¿¡æ¯ï¼ˆä»profilesè¡¨ï¼‰
        try:
            profile_response = supabase.table("profiles").select("*").eq("id", user_id).single().execute()
            user_data = profile_response.data if profile_response.data else {}
        except Exception as e:
            logging.warning(f"è·å–ç”¨æˆ·æ¡£æ¡ˆå¤±è´¥: {e}")
            user_data = {}
        
        # è¡¥å……emailä¿¡æ¯
        user_data["id"] = user_id
        user_data["email"] = user_email
        
        # è·å–ç”¨æˆ·åå¥½è®¾ç½®
        try:
            preferences_response = supabase.table("user_preferences").select("*").eq("user_id", user_id).single().execute()
            user_preferences = preferences_response.data if preferences_response.data else {}
        except Exception as e:
            logging.warning(f"è·å–ç”¨æˆ·åå¥½è®¾ç½®å¤±è´¥: {e}")
            user_preferences = {}
        
        # æ„å»ºå¯¼å‡ºæ•°æ®ç»“æ„
        export_data = {
            "export_info": {
                "exported_at": datetime.utcnow().isoformat(),
                "format": format,
                "user_id": user_id,
                "data_version": "1.0"
            },
            "user_profile": {
                "id": user_data["id"],
                "email": user_data["email"],
                "full_name": user_data.get("full_name"),
                "birth_datetime": user_data.get("birth_datetime"), # ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
                "gender": user_data.get("gender"),
                "birth_location": user_data.get("birth_location"), # ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
                "birth_timezone": user_data.get("birth_timezone"), # ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
                "timezone": user_data.get("timezone"),
                "created_at": user_data.get("created_at"),
                "updated_at": user_data.get("updated_at")
            },
            "preferences": user_preferences
        }
        
        # è·å–è¿åŠ¿æ•°æ®
        if include_fortunes:
            try:
                fortunes_response = supabase.table("fortune_history").select("*").eq("user_id", user_id).order("fortune_date", desc=True).execute()
                export_data["fortunes"] = fortunes_response.data if fortunes_response.data else []
            except Exception as e:
                logging.warning(f"è·å–è¿åŠ¿æ•°æ®å¤±è´¥: {e}")
                export_data["fortunes"] = []
        
        # è·å–æ—¥è®°æ•°æ®
        if include_diaries:
            try:
                diaries_response = supabase.table("diary_entries").select("*").eq("user_id", user_id).order("created_at", desc=True).execute()
                export_data["diaries"] = diaries_response.data if diaries_response.data else []
            except Exception as e:
                logging.warning(f"è·å–æ—¥è®°æ•°æ®å¤±è´¥: {e}")
                export_data["diaries"] = []
        
        # è·å–å¯¹è¯æ•°æ®
        if include_chats:
            try:
                chats_response = supabase.table("chat_messages").select("*").eq("user_id", user_id).order("created_at", desc=True).execute()
                export_data["chats"] = chats_response.data if chats_response.data else []
            except Exception as e:
                logging.warning(f"è·å–å¯¹è¯æ•°æ®å¤±è´¥: {e}")
                export_data["chats"] = []
        
        # æ ¹æ®æ ¼å¼è¿”å›æ•°æ®
        if format.lower() == "csv":
            return await _generate_csv_export(export_data)
        else:
            return export_data
            
    except Exception as e:
        logging.error(f"å¯¼å‡ºç”¨æˆ·æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¯¼å‡ºç”¨æˆ·æ•°æ®å¤±è´¥: {str(e)}")

async def _generate_csv_export(export_data: dict) -> Dict[str, Any]:
    """ç”ŸæˆCSVæ ¼å¼çš„å¯¼å‡ºæ•°æ®"""
    try:
        import csv
        import io
        
        # åˆ›å»ºCSVæ•°æ®
        csv_data = {}
        
        # ç”¨æˆ·æ¡£æ¡ˆCSV
        if "user_profile" in export_data:
            profile_buffer = io.StringIO()
            profile_writer = csv.writer(profile_buffer)
            profile_writer.writerow(["å­—æ®µ", "å€¼"])
            for key, value in export_data["user_profile"].items():
                profile_writer.writerow([key, str(value) if value is not None else ""])
            csv_data["user_profile"] = profile_buffer.getvalue()
            profile_buffer.close()
        
        # è¿åŠ¿æ•°æ®CSV
        if "fortunes" in export_data and export_data["fortunes"]:
            fortunes_buffer = io.StringIO()
            fortunes_writer = csv.writer(fortunes_buffer)
            
            # å†™å…¥è¡¨å¤´
            if export_data["fortunes"]:
                headers = list(export_data["fortunes"][0].keys())
                fortunes_writer.writerow(headers)
                
                # å†™å…¥æ•°æ®è¡Œ
                for fortune in export_data["fortunes"]:
                    row = [str(fortune.get(header, "")) for header in headers]
                    fortunes_writer.writerow(row)
            
            csv_data["fortunes"] = fortunes_buffer.getvalue()
            fortunes_buffer.close()
        
        # æ—¥è®°æ•°æ®CSV
        if "diaries" in export_data and export_data["diaries"]:
            diaries_buffer = io.StringIO()
            diaries_writer = csv.writer(diaries_buffer)
            
            if export_data["diaries"]:
                headers = list(export_data["diaries"][0].keys())
                diaries_writer.writerow(headers)
                
                for diary in export_data["diaries"]:
                    row = [str(diary.get(header, "")) for header in headers]
                    diaries_writer.writerow(row)
            
            csv_data["diaries"] = diaries_buffer.getvalue()
            diaries_buffer.close()
        
        # å¯¹è¯æ•°æ®CSV
        if "chats" in export_data and export_data["chats"]:
            chats_buffer = io.StringIO()
            chats_writer = csv.writer(chats_buffer)
            
            if export_data["chats"]:
                headers = list(export_data["chats"][0].keys())
                chats_writer.writerow(headers)
                
                for chat in export_data["chats"]:
                    row = [str(chat.get(header, "")) for header in headers]
                    chats_writer.writerow(row)
            
            csv_data["chats"] = chats_buffer.getvalue()
            chats_buffer.close()
        
        return {
            "format": "csv",
            "exported_at": export_data["export_info"]["exported_at"],
            "csv_files": csv_data,
            "note": "CSVæ•°æ®å·²ç”Ÿæˆï¼Œæ¯ä¸ªæ•°æ®ç±»å‹å¯¹åº”ä¸€ä¸ªCSVå­—ç¬¦ä¸²"
        }
        
    except Exception as e:
        logging.error(f"ç”ŸæˆCSVå¯¼å‡ºå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç”ŸæˆCSVå¯¼å‡ºå¤±è´¥: {str(e)}")

@router.delete("/export")
async def delete_exported_data(
    current_user: User = Depends(get_current_user)
):
    """
    åˆ é™¤å¯¼å‡ºçš„æ•°æ®ï¼ˆæ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼‰
    
    æ³¨æ„ï¼šè¿™åªæ˜¯æ¸…ç†æ“ä½œï¼Œä¸ä¼šåˆ é™¤ç”¨æˆ·çš„åŸå§‹æ•°æ®
    """
    try:
        user_id = str(current_user.id)
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ¸…ç†ä¸´æ—¶å¯¼å‡ºæ–‡ä»¶çš„é€»è¾‘
        # ç›®å‰è¿”å›æˆåŠŸæ¶ˆæ¯
        
        return {
            "message": "å¯¼å‡ºæ•°æ®æ¸…ç†å®Œæˆ",
            "user_id": user_id,
            "cleaned_at": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logging.error(f"æ¸…ç†å¯¼å‡ºæ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†å¯¼å‡ºæ•°æ®å¤±è´¥: {str(e)}") 

@router.delete("/account")
async def delete_user_account(current_user: User = Depends(get_current_user)):
    """åˆ é™¤ç”¨æˆ·è´¦å·åŠæ‰€æœ‰ç›¸å…³æ•°æ®ï¼ˆçº§è”åˆ é™¤ï¼‰"""
    try:
        user_id = str(current_user.id)
        user_email = current_user.email
        logging.info(f"[DELETE_ACCOUNT] ğŸ—‘ï¸ å¼€å§‹åˆ é™¤ç”¨æˆ·è´¦å·: user_id={user_id}, email={user_email}")
        
        # æ£€æŸ¥æ˜¯å¦é…ç½®äº† Service Role Key
        import os
        service_key = os.environ.get("SUPABASE_SERVICE_KEY")
        if not service_key:
            logging.error(f"[DELETE_ACCOUNT] âŒ æœªé…ç½® SUPABASE_SERVICE_KEYï¼Œæ— æ³•åˆ é™¤ç”¨æˆ·")
            raise HTTPException(
                status_code=500, 
                detail="æœåŠ¡å™¨é…ç½®é”™è¯¯ï¼šæœªé…ç½®ç®¡ç†å‘˜å¯†é’¥ã€‚è¯·è”ç³»ç®¡ç†å‘˜é…ç½® SUPABASE_SERVICE_KEYã€‚"
            )
        
        # åˆ›å»ºç‹¬ç«‹çš„ Admin Client æ‰§è¡Œåˆ é™¤æ“ä½œï¼ˆé¿å…è®¤è¯ä¸Šä¸‹æ–‡å†²çªï¼‰
        logging.info(f"[DELETE_ACCOUNT] ğŸ”§ åˆ›å»ºç‹¬ç«‹çš„ Admin Client...")
        from supabase import create_client
        admin_client = create_client(
            os.environ.get("SUPABASE_URL"),
            os.environ.get("SUPABASE_SERVICE_KEY")
        )
        logging.info(f"[DELETE_ACCOUNT] âœ… Admin Client åˆ›å»ºæˆåŠŸ")
        
        logging.info(f"[DELETE_ACCOUNT] ğŸ”§ è°ƒç”¨ Supabase Admin API åˆ é™¤ç”¨æˆ·...")
        
        try:
            # æ£€æŸ¥æ–¹æ³•æ˜¯å¦å­˜åœ¨
            if not hasattr(admin_client.auth, 'admin'):
                logging.error(f"[DELETE_ACCOUNT] âŒ admin_client.auth.admin ä¸å­˜åœ¨")
                raise HTTPException(
                    status_code=500,
                    detail="Supabase SDK ä¸æ”¯æŒ admin æ“ä½œï¼Œè¯·æ›´æ–° supabase-py åŒ…"
                )
            
            if not hasattr(admin_client.auth.admin, 'delete_user'):
                available_methods = [m for m in dir(admin_client.auth.admin) if not m.startswith('_')]
                logging.error(f"[DELETE_ACCOUNT] âŒ delete_user æ–¹æ³•ä¸å­˜åœ¨ï¼Œå¯ç”¨æ–¹æ³•: {available_methods}")
                raise HTTPException(
                    status_code=500,
                    detail=f"Supabase SDK ç¼ºå°‘ delete_user æ–¹æ³•ï¼Œå¯ç”¨: {', '.join(available_methods[:5])}"
                )
            
            # è°ƒç”¨åˆ é™¤æ–¹æ³•ï¼ˆshould_soft_delete=False è¡¨ç¤ºæ°¸ä¹…åˆ é™¤ï¼‰
            logging.info(f"[DELETE_ACCOUNT] ğŸ”§ æ‰§è¡Œ delete_user({user_id})...")
            result = admin_client.auth.admin.delete_user(user_id, should_soft_delete=False)
            logging.info(f"[DELETE_ACCOUNT] ğŸ“‹ åˆ é™¤ç»“æœ: {result}")
            
        except HTTPException:
            raise
        except AttributeError as ae:
            logging.error(f"[DELETE_ACCOUNT] âŒ Supabase SDK AttributeError: {ae}", exc_info=True)
            raise HTTPException(
                status_code=500,
                detail=f"Supabase SDK æ–¹æ³•è°ƒç”¨å¤±è´¥: {str(ae)}"
            )
        except Exception as delete_error:
            logging.error(f"[DELETE_ACCOUNT] âŒ Supabase åˆ é™¤å¤±è´¥: {delete_error}", exc_info=True)
            logging.error(f"[DELETE_ACCOUNT] âŒ é”™è¯¯ç±»å‹: {type(delete_error)}")
            raise HTTPException(
                status_code=500,
                detail=f"åˆ é™¤ç”¨æˆ·å¤±è´¥: {str(delete_error)}"
            )
        
        # éªŒè¯ç”¨æˆ·æ˜¯å¦çœŸçš„è¢«åˆ é™¤ï¼ˆå°è¯•æŸ¥è¯¢ç”¨æˆ·ï¼‰
        try:
            check_user = admin_client.auth.admin.get_user_by_id(user_id)
            if check_user:
                logging.warning(f"[DELETE_ACCOUNT] âš ï¸ ç”¨æˆ·å¯èƒ½æœªè¢«å®Œå…¨åˆ é™¤ï¼Œä»å¯æŸ¥è¯¢åˆ°: {check_user}")
        except:
            logging.info(f"[DELETE_ACCOUNT] âœ… éªŒè¯é€šè¿‡ï¼šç”¨æˆ·å·²ä» auth.users ä¸­åˆ é™¤")
        
        logging.info(f"[DELETE_ACCOUNT] âœ… ç”¨æˆ·è´¦å·åˆ é™¤æˆåŠŸ: user_id={user_id}")
        return {"message": "è´¦å·åˆ é™¤æˆåŠŸ", "deleted_at": datetime.utcnow().isoformat()}
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"[DELETE_ACCOUNT] âŒ åˆ é™¤è´¦å·å¤±è´¥: user_id={current_user.id if current_user else 'unknown'}, error={e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆ é™¤è´¦å·å¤±è´¥: {str(e)}")
